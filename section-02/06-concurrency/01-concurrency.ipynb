{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency\n",
    "\n",
    "A **concurrent** program is one consisting of multiple threads executing \"at the same time\" and independently.\n",
    "\n",
    "A **thread** is an independent line of execution within a process.\n",
    "\n",
    "A thread has its own set of registers (its context!) on the CPU.\n",
    "\n",
    "A thread has its own stack.\n",
    "\n",
    "A thread its own instruction pointer (aka program counter).\n",
    "\n",
    "Within a process, the rest of the address space is shared amongst all of its threads:\n",
    "\n",
    "- heap\n",
    "- code block\n",
    "- static global block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"images/01-AS.png\" width=\"500\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why talk about concurrency in OS?\n",
    "\n",
    "The OS is the first concurrent program and needs to support concurrency in order to exist.\n",
    "\n",
    "The mechanisms to support concurrency are critical to a computer operating safely and must be with the OS's purview.\n",
    "\n",
    "Concurrency is useful if we can paralellize programs. If we can split some algorithm or overal program into threads and execute them independently at the same time, we can save time overall.\n",
    "\n",
    "Concurrency is also very useful in IO intensive applications.\n",
    "\n",
    "Web servers are multithreaded. When a request comes in, a new thread is created specifically to handle that request so that the server can continue to accept other requests and handle multiple requests at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Major Challenge of Concurrency\n",
    "\n",
    "Concurrent programs can execute in a non-deterministic order because we (the programmers) don't have control over when the threads will be executed.\n",
    "\n",
    "The order is determined by the CPU scheduler.\n",
    "\n",
    "The is especially problematic when multiple threads are attempting to access shared data.\n",
    "\n",
    "If multiple threads are trying to update shared data, and they can be interrupted while doing so, that data can get corrupted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "Any set of instructions which should not be interrupted if want our program to be correct is known as **critical section**.\n",
    "\n",
    "We want all critical sections to be **atomic**.\n",
    "\n",
    "A set of instructions is **atomic** if it will run to completion for any individual thread before any other thread can start executing them.\n",
    "\n",
    "If multiple threads end up in the same critical section at the same time, we have a **race condition**.\n",
    "\n",
    "To avoid race conditions, to ensure that critical sections are atomic, we use **locks**.\n",
    "\n",
    "We will explore how to use and build locks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use a lock\n",
    "\n",
    "A **lock** is a variable that only one thread can hold at a time.\n",
    "\n",
    "If we put a lock around a critical section, only one thread can access it at a time. We are making that critical section mutually exclusive.\n",
    "\n",
    "To use a lock, a program instaniates it, then attempts to hold it before entering some critical section, and finally upon leaving the critical section, releases it.\n",
    "\n",
    "```c\n",
    "lock_t mutex; //declare the lock, mutex for mutual exclusion\n",
    "init(&mutex); // initialize the lock\n",
    "// ..\n",
    "lock(&mutex); // attemp to grab the lock\n",
    "sharedVariable++; // critical section\n",
    "unlock(&mutex); // release the lock\n",
    "```\n",
    "\n",
    "If thread A holds the lock when thread attempts to grab it, then thread B must wait until A releases the lock before it can get it and continue execution.\n",
    "\n",
    "In this way, we ensure that only one thread can be in the critical section at a time.\n",
    "\n",
    "A program can create and use multiple locks.\n",
    "\n",
    "If there are multiple critical sections, it is best to have a lock per critical section so that different threads can be in different critical sections at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Lock\n",
    "\n",
    "## Goals\n",
    "\n",
    "**Correctness**: Our lock should correctly ensure mutually exclusive access to critical sections\n",
    "\n",
    "**Fairness**: If we multiple threads all vying for the same lock, eventually each thread should get the lock. We don't want to starve our threads.\n",
    "\n",
    "**Performance**: Minimize overhead. Within a single thread, the overhead should be minimal. Over the whole system, we want to minimize the overall time spent waiting for locks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Locks\n",
    "\n",
    "To implement a lock, we need to implement:\n",
    "\n",
    "1) Lock initialization\n",
    "\n",
    "2) locking it\n",
    "\n",
    "3) releasing a lock\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A First Lock\n",
    "\n",
    "Simple idea: use a flag.\n",
    "\n",
    "If the flag is 0, the lock is available.\n",
    "\n",
    "If the flag is 1, the lock is unavailable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "typedef struct lock_t {\n",
    "  // data for the lock\n",
    "  short flag;\n",
    "} lock_t;\n",
    "\n",
    "void init(lock_t &mutex){\n",
    "  // init code\n",
    "  mutex->flag = 0; // 0->available, 1->held\n",
    "}\n",
    "\n",
    "void lock(lock_t &mutex) {\n",
    "  // aquire the lock\n",
    "  while(mutex->flag == 1) {\n",
    "    ; // spin, wait for the lock to become free\n",
    "  }\n",
    "  mutex->flag = 1;\n",
    "}\n",
    "\n",
    "void unlock(lock_t &mutex) {\n",
    "  // release the lock\n",
    "  mutex->flag = 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lock is not correct because the `lock()` function can get interrupted between TESTING the flag and SETTING it to be held.\n",
    "\n",
    "Suppose Thread A tests the lock, seeing that it is available. It is them immediately interrupted after exiting the while loop but before updating the flag. \n",
    "\n",
    "Thread B calls lock, sees that it is available, updates the flag, enters the critical section, and is interrupted before leaving the critical section.\n",
    "\n",
    "Thread A then continues to run, updates the lock, enters the critical section, and we now have BOTH Thread A and B in the critical section at the same time.\n",
    "\n",
    "Unfortunately, there is NO single C instruction that allows for a variable to be queried and updated at the same time.\n",
    "\n",
    "We need additional support, hardware support to enable us to build correct locks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Support\n",
    "\n",
    "There is a set of concurrency primitives built into the CPU which can not be interrupted.\n",
    "\n",
    "## Test and Set\n",
    "\n",
    "We lacked the ability to check and update a flag atomically.\n",
    "\n",
    "Expressed as C code:\n",
    "\n",
    "```c\n",
    "// update and return old flag atomically\n",
    "int TestAndSet(int *flag, int newValue) {\n",
    "  int old = *flag;\n",
    "  *flag = newValue;\n",
    "  return old;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A correct spin lock\n",
    "\n",
    "```c\n",
    "typedef struct lock_t {\n",
    "  // data for the lock\n",
    "  short flag;\n",
    "} lock_t;\n",
    "\n",
    "void init(lock_t &mutex){\n",
    "  // init code\n",
    "  mutex->flag = 0; // 0->available, 1->held\n",
    "}\n",
    "\n",
    "void lock(lock_t &mutex) {\n",
    "  // aquire the lock\n",
    "  while(TestAndSet(&(mutex->flag), 1)) {\n",
    "    ; // spin, wait for the lock to become free\n",
    "  }\n",
    "}\n",
    "\n",
    "void unlock(lock_t &mutex) {\n",
    "  // release the lock\n",
    "  mutex->flag = 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the flag is available (flag==0), it will be set to 1, and 0 will be returned, breaking us out of the loop and allowing this thread to enter the critical section.\n",
    "\n",
    "If the flag is unavailable (flag==1), it will be set to 1 (no change), and 1 will be returned, forcing the loop to execute again.\n",
    "\n",
    "We have a correct solution, all instructions to deal with the flag are atomic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance and Fairness analysis\n",
    "\n",
    "This is inefficient because a waiting thread will waste CPU cycles spinning inside of the while loop.\n",
    "\n",
    "One solution would be to `yield()` the CPU. If the lock isn't available, give up the CPU.\n",
    "\n",
    "If the thread that holds the lock is waiting on a CPU, it might get CPU time quicker."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
