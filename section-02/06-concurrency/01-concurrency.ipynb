{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency\n",
    "\n",
    "A **concurrent** program is one consisting of multiple threads executing \"at the same time\" and independently.\n",
    "\n",
    "A **thread** is an independent line of execution within a process.\n",
    "\n",
    "A thread has its own set of registers (its context!) on the CPU.\n",
    "\n",
    "A thread has its own stack.\n",
    "\n",
    "A thread its own instruction pointer (aka program counter).\n",
    "\n",
    "Within a process, the rest of the address space is shared amongst all of its threads:\n",
    "\n",
    "- heap\n",
    "- code block\n",
    "- static global block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"images/01-AS.png\" width=\"500\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why talk about concurrency in OS?\n",
    "\n",
    "The OS is the first concurrent program and needs to support concurrency in order to exist.\n",
    "\n",
    "The mechanisms to support concurrency are critical to a computer operating safely and must be with the OS's purview.\n",
    "\n",
    "Concurrency is useful if we can paralellize programs. If we can split some algorithm or overal program into threads and execute them independently at the same time, we can save time overall.\n",
    "\n",
    "Concurrency is also very useful in IO intensive applications.\n",
    "\n",
    "Web servers are multithreaded. When a request comes in, a new thread is created specifically to handle that request so that the server can continue to accept other requests and handle multiple requests at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Major Challenge of Concurrency\n",
    "\n",
    "Concurrent programs can execute in a non-deterministic order because we (the programmers) don't have control over when the threads will be executed.\n",
    "\n",
    "The order is determined by the CPU scheduler.\n",
    "\n",
    "The is especially problematic when multiple threads are attempting to access shared data.\n",
    "\n",
    "If multiple threads are trying to update shared data, and they can be interrupted while doing so, that data can get corrupted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "Any set of instructions which should not be interrupted if want our program to be correct is known as **critical section**.\n",
    "\n",
    "We want all critical sections to be **atomic**.\n",
    "\n",
    "A set of instructions is **atomic** if it will run to completion for any individual thread before any other thread can start executing them.\n",
    "\n",
    "If multiple threads end up in the same critical section at the same time, we have a **race condition**.\n",
    "\n",
    "To avoid race conditions, to ensure that critical sections are atomic, we use **locks**.\n",
    "\n",
    "We will explore how to use and build locks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use a lock\n",
    "\n",
    "A **lock** is a variable that only one thread can hold at a time.\n",
    "\n",
    "If we put a lock around a critical section, only one thread can access it at a time. We are making that critical section mutually exclusive.\n",
    "\n",
    "To use a lock, a program instaniates it, then attempts to hold it before entering some critical section, and finally upon leaving the critical section, releases it.\n",
    "\n",
    "```c\n",
    "lock_t mutex; //declare the lock, mutex for mutual exclusion\n",
    "init(&mutex); // initialize the lock\n",
    "// ..\n",
    "lock(&mutex); // attemp to grab the lock\n",
    "sharedVariable++; // critical section\n",
    "unlock(&mutex); // release the lock\n",
    "```\n",
    "\n",
    "If thread A holds the lock when thread attempts to grab it, then thread B must wait until A releases the lock before it can get it and continue execution.\n",
    "\n",
    "In this way, we ensure that only one thread can be in the critical section at a time.\n",
    "\n",
    "A program can create and use multiple locks.\n",
    "\n",
    "If there are multiple critical sections, it is best to have a lock per critical section so that different threads can be in different critical sections at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Lock\n",
    "\n",
    "## Goals\n",
    "\n",
    "**Correctness**: Our lock should correctly ensure mutually exclusive access to critical sections\n",
    "\n",
    "**Fairness**: If we multiple threads all vying for the same lock, eventually each thread should get the lock. We don't want to starve our threads.\n",
    "\n",
    "**Performance**: Minimize overhead. Within a single thread, the overhead should be minimal. Over the whole system, we want to minimize the overall time spent waiting for locks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
